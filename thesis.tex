\RequirePackage{tikz}
% Opcje klasy 'iithesis' opisane sa w komentarzach w pliku klasy. Za ich pomoca
% ustawia sie przede wszystkim jezyk i rodzaj (lic/inz/mgr) pracy, oraz czy na
% drugiej stronie pracy ma byc skladany wzor oswiadczenia o autorskim wykonaniu.
\documentclass[english,shortabstract,mgr]{iithesis}

\usepackage[utf8]{inputenc}
\usepackage{ulem}
\usepackage{amsthm}
\usepackage{subcaption}
\usepackage{cite}
\usepackage{float}

\usetikzlibrary{shapes.multipart}
\usetikzlibrary{decorations.text}
\usetikzlibrary{automata}


%%%%% DANE DO STRONY TYTUŁOWEJ
% Niezaleznie od jezyka pracy wybranego w opcjach klasy, tytul i streszczenie
% pracy nalezy podac zarowno w jezyku polskim, jak i angielskim.
% Pamietaj o madrym (zgodnym z logicznym rozbiorem zdania oraz estetyka) recznym
% zlamaniu wierszy w temacie pracy, zwlaszcza tego w jezyku pracy. Uzyj do tego
% polecenia \fmlinebreak.
\polishtitle    {Tłumaczenie współczesnego języka programowania\fmlinebreak do Maszyny Minsky'ego.}
\englishtitle   {Modern programming language translation to the theoretical model of Minsky Machine (Counter Machine).}
\polishabstract {TODO: polishabstract}
\englishabstract{
Counter Machine (a machine with finite state set, two counters and input/output tape) is~able to express any
computations done by~modern programming languages. This is~the~well-known theorem, just like computations
performed using Turing Machine and~means that anything written in a~modern programming language is possible
to~translate into the~theoretical model of Minsky Machine (as well as into Turing Machine).

My goal is to build automatic translation from a~modern programming language (C++) to Minsky Machine.
}
% w pracach wielu autorow nazwiska mozna oddzielic poleceniem \and
\author         {Jadwiga Pokorska}
% w przypadku kilku promotorow, lub koniecznosci podania ich afiliacji, linie
% w ponizszym poleceniu mozna zlamac poleceniem \fmlinebreak
\advisor        {dr Jakub Michaliszyn}
%\date          {}                     % Data zlozenia pracy
% Dane do oswiadczenia o autorskim wykonaniu
\transcriptnum {247906}                     % Numer indeksu
\advisorgen    {dr Jakuba Michaliszyna} % Nazwisko promotora w dopelniaczu
%%%%%

%%%%% WLASNE DODATKOWE PAKIETY
%
%\usepackage{graphicx,listings,amsmath,amssymb,amsthm,amsfonts,tikz}
%
%%%%% WŁASNE DEFINICJE I POLECENIA
%
%\theoremstyle{definition} \newtheorem{definition}{Definition}[chapter]
%\theoremstyle{remark} \newtheorem{remark}[definition]{Observation}
%\theoremstyle{plain} \newtheorem{theorem}[definition]{Theorem}
%\theoremstyle{plain} \newtheorem{lemma}[definition]{Lemma}
%\renewcommand \qedsymbol {\ensuremath{\square}}
% ...
%%%%%

%\usepackage{todonotes}

\newcommand{\todo}[1]{\textbf{TODO:} #1}
\newtheorem*{hypothesis}{Hypothesis}

\begin{document}

%%%%% POCZĄTEK ZASADNICZEGO TEKSTU PRACY

\chapter{Introduction}

\section{Turing Machine}

Modern computers and their abilities nowadays are complex and depend on many different factors
to~perform given computations, like processor technology, software optimizations within given
processor model, input/output communication protocols and many others. This is why if we want
to~state or proof anything about the behaviour of computer programs then we need to~find a~common
language and~general theoretical model representing any type of "computer".

The model is known since 1936 \cite{sipser2012ChurchTuring} when Alan Turing proposed something
called \textbf{Turing Machine}
to represent a~machine that is able to~execute any computations expressible in~terms of~computer program.
It has all positive and~negative properties which belong to~modern programs, i.e. it~is possible
to create a~program which will never stop or~consume infinite amount of memory. The model does not allow
to~solve all the problems -- it~has got the~same limitations in~sense of~creating algorithms
like a~regular computer.

Turing Machine is~a~finite description of~an~algorithm and~uses potentially infinite tape
as~its memory -- we have some amount of~tape at~the beginning, but~we may extend this tape
(glue additional tape cells) to~the right end if necessary. All cells are either blank
or~contain a~single letter -- when machine starts its work there is an~input word
written on~the tape, during computations the~machine is allowed to~change all the available
cells and~after it finishes (if it finishes at all) it can either \textit{accept}
or~\textit{reject} original input word.

As~an~example we can try to construct Turing Machine recognizing all binary palindromes of~even length,
which is~formally set $A = \{ ww^R : w \in \{0,1\}^* \}$ (where $^R$ means reversing given word).

Because we need to use finite description to~define behaviour we say that the~machine should
check first letter $a_1$ with last one $a_n$ -- if these cells contain different letters machine
should reject the whole word, otherwise it should mark them as checked (i.e. write $\#$ symbol in~their cells)
and~continue with $a_2$ and~$a_{n-1}$. At~the~end we should have tape full of $\#$s and~the~machine
should accept given word. If there is just one unchanged cell left then it was a~palindrome
of~odd length and~we should reject it.

\textbf{Turing Machine} is a~$6$-tuple $(Q,\Sigma,\Gamma,\delta,q_0,P)$ where:
\begin{itemize}
  \item $Q$ is~a~finite set of~states the~machine can be within,
  \item $\Sigma$ is~a~finite input alphabet (does not contain blank),
  \item $\Gamma$ is~a~finite tape alphabet and~$\Sigma \subset \Gamma$,
  \item $\delta: Q \times \Gamma \rightarrow Q \times \Gamma \times \{L,R\}$ is~a~finite
      transition function, $L$ and~$R$ mean the~machine should move one cell left or~right
      respectively,
  \item $q_0$ is~the~initial state the~machine starts within,
  \item $P$ is~a~finite set of~states which accept the~input word.
\end{itemize}

\textbf{Configuration} of~a~Turing Machine consists of ($w$, $q$, $k$), where:
\begin{itemize}
  \item $w \in \Sigma^*$ is a~word initially written on~the~tape,
  \item $q$ is a~state of the~machine is~currently within,
  \item $k$ is a~cell number the~machine is currently looking at.
\end{itemize}

Having a~configuration we can precisely say what is the~program execution progress.
One configuration is~a~precise step of~computation, so a~sequence of~configurations is called
a~\textbf{run} of~a~Turing Machine. This sequence may be finite or~infinite the~same way like
a~program may loop forever or~finish within some number of~steps. Each such run begins with
a~configuration where some word $w$ is~an~input, $k = 0$ which is the~leftmost cell on~the~tape
and~$q = q_0$ which is initial state defined in~the~description of~given machine. If~a~run is
finite and~ends with configuration ($w_n$, $q_n$, $k_n$) then we define the~input word to~be
\textit{accepted} if $q_n \in P$ ($q_n$ is one of accepting states) and \textit{rejected} otherwise.

\section{Church-Turing thesis and Turing-completeness}

Computers are used to perform calculations for us, more precicely we want them to~execute some
procedures or~to~perform some process and~we call it an~\textit{algorithm} in~its intuitive meaning.
A~good example could be~a~mathematical problem of~generating prime numbers -- it~is fairly simple
to~think of~a~method of~generating prime numbers by checking lager and~larger numbers and~checking
their all possible divisors. We~are able to~precisely say what this algorithm looks like and~if
we think for a~while we would probably be able to~express it in terms of Turing Machines. That
is~exactly what \textbf{Church-Turing thesis} \cite{sipser2012ChurchTuring} states:

\begin{hypothesis}
  Intuitive definition of~any~algorithm is~equivalent to~some description of~Turing Machine.
\end{hypothesis}

This thesis allows us to~think about defining algorithms in~intuitive way while still staying
within the~world of~Turing Machine programs.

It~turns out that when designing any~modern algorithms we use~the same way of~intuitive description
of~a~procedure and~then we~are converting it~into \textit{implementation} which is~a~representation
of~given algorithm using a~modern programming language. From thesis above we~claim that most probably
it~would be~possible to~express it~as~a~Turing Machine (but probably require lots of~thought).

To~avoid~a~painful process of~expressing algorithms in~an~unhandy theoretical model we~have
a~concept of~\textbf{Turing-completeness}. All popular modern programming languages are proven
to~be Turing-complete which means that we are able to~implement our algorithm in~such
language if and only if there exists some equivalent Turing Machine description.

\section{Counter Machine}

We have so far theoretical model -- Turing Machine -- which has the~same power of~expression
as~modern languages and~it turns out there are many others we~can describe and~prove they are
equivalent to Turing Machine (so~to~modern languages as~well). One of~such alternatives
is~\textbf{Counter Machine} (sometimes called \textbf{Minsky Machine}) \cite{minsky_67}
which is~really basic in~its construction.

Similarly to~Turing Machine, Counter Machine has~finite description -- finite set of~states $Q$
and~transition function $\delta$ defining when the~machine may move from one state to~another.
Instead of~the~infinite tape there are $2$ counters -- each counter works like a~glass of~coins,
the~machine may throw a~coin (or~several coins) into the~glass, check whether the~glass is~empty
or~take out a~coin (only one and~only if glass is not empty). Each counter is~basically a~non-negative
integer, but the~machine is~not allowed to~explicitly check its value, it~just gets boolean
information about emptiness.

There are a~few alternative models -- if~we~allow the~machine to~use $3$ counters instead of~$2$
then we get equivalent model, the~same for $4$ or~more counters. According to~this fact, we~can
choose how many counters it~is convenient for~us to~use. The~only exception is~Counter Machine with
$1$ counter which is~not able to~express everything a~$2$ Counter Machine can. As~an~argument
we may say that halting problem for $1$ Counter Machine is~decidable -- it is possible to~check
in~polynomial time whether given description of $1$ Counter Machine will loop forever or~not.
Of~course halting problem for $2$ Counter Machine (which is~equivalent to~Turing Machine model)
is proven to~be not decidable. \cite{minsky_67}

\section {2 stack pushdown automaton (2 stack PDA)}

Similarly to~Counter Machine, finite description of a~2~stack pushdown automaton \cite{sipser2012PDA}
contains number of~states and~transition function $\delta$, but~counters are replaced with 2 stacks.
These 2~stacks use stack alphabet $\Gamma$ and the~automaton may change their state
by~pushing zero or~more symbols at the~top or~removing \textbf{exactly one} symbol from
the~top.

In practice the~implementation assumes that a~single transition \textbf{always} takes
a~symbol from each stack and after transitioning to a~new state pushes some symbols
(maybe the~original ones) to each stack.

Each stack has a~special symbol $\perp$ at the~bottom that determines when a~stack becomes
empty. Additionally it is not allowed to take $\perp$ out from the stack, so~after transitioning
to a~new state $\perp$ must be pushed back (maybe followed by other symbols) to~the~stack.

Formally 2 stack PDA is a~$6$-tuple ($Q$, $\Sigma$, $\Gamma$, $\delta$, $q_0$, $F$) where:
\begin{itemize}
  \item $Q$ is a~finite set of states,
  \item $\Sigma$ is a~finite input alphabet ($\epsilon \in \Sigma$),
  \item $\Gamma$ is a~finite stack alphabet ($\perp \in \Gamma$),
  \item $\delta: Q \times \Sigma \times \Gamma \times \Gamma \rightarrow
      Q \times \Gamma^* \times \Gamma^*$ is~a~finite transition function,
  \item $q_0$ is the initial state of the~PDA,
  \item $F$ is a~finite set of states which accept the~input word.
\end{itemize}

Each transition specifies when it may be applied by giving a~triple
($a$,~$s$,~$t$)~$\in$~($\Sigma$,~$\Gamma$,~$\Gamma$). It means that input symbol is $a$,
the~left stack has symbol $s$ and the~right stack symbol $t$ at the~top. In practice there
might be multiple transitions matching current state, so it is assumed that the first one
defined is applied.

\section{Brainfuck}

As~we defined above Counter Machine is~a~minimalistic model of~computations, the~same way
\textbf{Brainfuck} \cite{brainfuckWiki} is a~minimalistic (only 8 instructions) programming
language which recalls
the~definition of~Turing Machine -- program operates on~a~tape containing numbers, it~is possible
to~explicitly read and~change values in~cells. A~program operates on~a~data pointer which
points to~the~current focus cell, so~that it~is able to~freely move around. The~main difference
between Turing Machine and~Brainfuck is~lack of~states and~transitions, instead a~program
is a~sequence of intructions that are executed one by~one.

Usually Brainfuck implementations assume that tape length is~around $30\,000$ cells which
is~enough in~most cases. If~we want to~prove Turing-completeness though, this tape
needs to~be potentially infinite. Of couse, no~modern machine is~equipped with infinite memory,
but we are able to~extend it (with buying additional hardware), so~this factor is~omitted
when proving Turing-completeness. It is not a~problem in~this thesis at~all since
the~main goal is to~show that anything written in~modern programming language is~possible
to~automatically translate into~theoretical model.

\section {Purpose of this thesis}

This~thesis should be~a~proof of~theoretical concept based on~Church-Turing thesis -- any~algorithm
or~mathematical method we~are able to~come up with (as~long as it is expressible in any programming
language) is possible to~execute on~the~most basic theoretical model which is a~Counter Machine.

Implementation translates Brainfuck into Counter Machine model and~consists of~a~few separate parts
which are completely separate translations between more and more besic theoretical models.
It is possible to access any transitional (temporary) programs created during the~whole process.

The~plan of translation including transitional models:

\hspace{-1.5cm}
\begin{tikzpicture}
  \draw (0,0) rectangle (2,1) node[pos=.5] {Brainfuck};
  \draw (3,0) rectangle (5,1) node[pos=.5, text width=2cm, align=center] {Turing Machine};
  \draw (6,0) rectangle (8,1) node[pos=.5, text width=2cm, align=center] {2 Stack PDA};
  \draw (9,-0.5) rectangle (12,1.5) node[pos=.5, text width=2.5cm, align=center] {Counter Machine \\ 4 Counters};
  \draw (13,-0.5) rectangle (16,1.5) node[pos=.5, text width=2.5cm, align=center] {Counter Machine \\ 2 Counters};
  \draw [->, >=stealth] (2,0.5) -- (3,0.5);
  \draw [->, >=stealth] (5,0.5) -- (6,0.5);
  \draw [->, >=stealth] (8,0.5) -- (9,0.5);
  \draw [->, >=stealth] (12,0.5) -- (13,0.5);
\end{tikzpicture}

Any two consecutive models have automatic translation, so we may wish to~start with any program written
in Brainfuck, Turing Machine, 2 stack PDA or~4 Counter Machine and receive an~equivalent 2 Counter Machine.
Similarly we may stop at any point of~translations, so it is possible to generate an equvalent program
in 2 stack PDA model from a~program written in Turing Machine model.

The~flexibility in running the~pipeline gives us possibility to prove (as~side-effect)
the~original Church-Turing thesis. Any~modern program (written in Brainfuck) may be executed
on a~theoretical Turing Machine model.


\todo{Co to są \sout{maszyny Turinga, Mińskiego, Brainfuck, Turning-zupełność, hipoteza Churcha}}

\todo{O czym jest ta praca - lista kontrybucji}

\todo{\sout{Po co jest ta praca --- ,,proof of concept''; ,,walory dydaktyczne'', }\dots}

\todo{,,Related work''}

\todo{Plan pracy}

\ldots

\chapter {Preliminaries}

\section {Brainfuck}

Brainfuck is a programming language with only $8$ statements and execution
of~any program is done using a~finite sequence of~memory cells. Statements
operate on~these cells using data pointer --- initially the pointer is set
on the~leftmost cell in the sequence.

Statements:
\begin{itemize}
  \item \texttt{>} moves the data pointer one cell to the right,
  \item \texttt{<} moves the data pointer one cell to the left,
  \item \texttt{+} increase by $1$ the value held in the cell under the data pointer,
  \item \texttt{-} decrease by $1$ the value held in the cell under the data pointer,
  \item \texttt{.} print to stdout the~character that is under the~data pointer,
  \item \texttt{,} read from stdin a~character and write it to the cell under the data pointer,
  \item \texttt{$[$} beginning of a loop with condition checking whether value under
      the~data pointer is zero. If it is then execution jumps to the matching $]$,
  \item \texttt{$]$} closing symbol of a loop --- execution jumps to the~beginning of the~loop
      (matching $[$) and then check for zero value under the data pointer is performed.
\end{itemize}

It is allowed to use any other characters within the code, but anything else than the $8$
listed above are ignored --- it is useful for creating comments in the code.

An example code printing "Hello World!":
\begin{verbatim}
++++++++++
[
>+++++++>++++++++++>+++>+<<<<-
] We set up the values in few cells for future use.
>++.               prints 'H'
>+.                prints 'e'
+++++++.           prints 'l'
.                  prints 'l'
+++.               prints 'o'
>++.               prints space
<<+++++++++++++++. prints 'W'
>.                 prints 'o'
+++.               prints 'r'
------.            prints 'l'
--------.          prints 'd'
>+.                prints '!'
>.                 prints newline character
\end{verbatim}

\section {Turing Machine}

\subsection {Instructions}

Turing Machine consists of a finite number of states, changes between them
and~potentially infinite tape, on~which it is able to~write and~read symbols.
It has no code sequence, a program is a~set of state changes and~definition
of~an~initial state. There is special final state \texttt{END} that does not need
        to~be defined to~be used.

There is a~predefined set of symbols used on the tape which is whole ASCII character set
extended with the same amount of additional (non-ASCII) symbols. Regular
ASCII characters have 7 bits (numbers 0-127), so tape symbols have 8 bits
allowing to hold regular ASCII and special characters (numbers 128-255).

        There are few special definitions (so far using regular ASCII,
but it will be changed to use special characters instead):
\begin{itemize}
  \item \texttt{BLANK} which represents empty field on the tape
  \item \texttt{*} (ALL) defines all characters (both ASCII and special)
  \item \texttt{\#} (NOTHING) means no character which is used to say
                   that we do not want to write anything on tape during
                   this state change
          \item \texttt{\&} (NON-ZERO) defines all characters except 0
          \item \texttt{0} (ZERO) represents zero that is used for conditional jumps
           (jump zero)
          \item \texttt{>} (NEXT-CHAR) allows writing on the tape next character
                   (increased by one), i.e. writes \texttt{g} if on the tape
                   was \texttt{f}
  \item \texttt{<} (PREV-CHAR) similarly as above but writes the previous character,
                   i.e. writes \texttt{e} when seen \texttt{f}
\end{itemize}

Defining initial state:
\begin{verbatim}
START: state_name
\end{verbatim}

Each state change looks as follows:
\begin{verbatim}
state_name symbol(s) -> target_state head_move symbol_to_write
\end{verbatim}

\texttt{symbol(s)} is ASCII character including special definitions (currently
all special definitions use regular ASCII so that it is easy to see
in a~standard text file), in future it will allow getting non-ASCII special
characters as well.

\texttt{head move} is one of \texttt{L}, \texttt{R} or \texttt{-} which
steer the head to go left, right or stay in place, respectively.

\texttt{symbol to write} is any (currently ASCII) symbol. Currently, there
is no mechanism to prevent writing any symbol from special definitions,
but~it will cause an~undefined behaviour of~the machine. The only symbol
from special definitions that is allowed to appear as \texttt{symbol\_to\_write}
is \texttt{\#} (NOTHING) meaning that symbol on the tape should not change.

\subsection {Extensions of the theoretical model}

Standard input/output handling is done by allowing to read or write single
ASCII character from/to stdin/stdout. It is possible to~add additional
reading or~writing before moving the~head. It is done by modifying change
symbol \texttt{->} in the~state change definition.
\begin{itemize}
  \item Reading is done with \texttt{->*}, i.e. \texttt{state1 A ->* state2 R NOTHING}
        which means when seen symbol \texttt{A} in state \texttt{state1} we read
        from stdin one character, overwrite \texttt{A} to read value and move
        head one field right.
  \item Writing is done similarly with \texttt{->\^},
        i.e. \texttt{state1 A ->\^ state2 R NOTHING} which will print symbol
        \texttt{A} on stdout and move the~head to the~right.
\end{itemize}

\subsection{Example}

A~program that reads a~letter from stdin, writes this letter into
stdout and if the~written letter was \texttt{B} or \texttt{b} then prints
\texttt{.} at the end as well, otherwise finishes.

\begin{verbatim}
START: s1
s1 ALL ->* s2 - NOTHING
s2 ALL ->^ s3 - NEXT_CHAR
s3 ALL -> s4 - NOTHING
s4 b ->^ s5 R NOTHING
s4 B ->^ s5 R NOTHING
s5 ALL -> s6 - .
s6 ALL ->^ s7 - NOTHING
s7 ALL -> END - NOTHING
\end{verbatim}

Note: If there is no state change defined for given configuration
(nothing matches) then it is assumed that machine gets to \texttt{END} state.
Because of this in the above example, last instruction is not necessary.

\section {2 Stack Pushdown Automaton}

2 Stack Pushdown Automaton consists of two stacks, input tape and~definition
of~states and transitions between them. Each transition looks as follows:
\begin{verbatim}
state_name left_pattern right_pattern ->
    target_state left_stack_items right_stack_items
\end{verbatim}

Explanation:
\begin{itemize}
  \item \texttt{left\_pattern} is symbol or pattern that should be matched
      for the symbol at the top of the left stack
  \item \texttt{right\_pattern} is the same as above, but for right stack
  \item \texttt{left\_stack\_items} are the list of items that should be pushed
      to the~left stack before moving to \texttt{target\_state}. It might be
      a~single letter \texttt{"a"}, a~sequence of letters \texttt{"abc"}
      or~sequence of~letters and~references, i.e. \texttt{("a" + ORIG\_LEFT + "b")}
      where \texttt{ORIG\_LEFT} means the letter we read from the~left stack (the one matched
      in \texttt{left\_pattern}). Note: If \texttt{+} is used it is required to put
      the~whole sequence in parenthesis
  \item \texttt{right\_stack\_items} are the same as above, but for items to be pushed into right stack
\end{itemize}

Special references and definitions in transitions:
\begin{itemize}
  \item \texttt{ORIG\_LEFT} is the letter taken from the left stack
  \item \texttt{ORIG\_RIGHT} is the letter taken from right stack
  \item \texttt{INPUT\_CHAR} is the letter taken from input tape
      (only in input transition type - see section below)
  \item \texttt{NOTHING} may be used as \texttt{left\_stack\_items} or \texttt{right\_stack\_items}
      and means that nothing is pushed into left/right stack
  \item \texttt{END} is special state name into which the transition is made if no other transition is specified
  \item \texttt{\$} is the symbol of the empty stack
\end{itemize}

\subsection {Extensions of the theoretical model}

Input/Output handling is done similarly to Turing Machine - We change \texttt{->} in transition
to \texttt{->*} or \texttt{->\^}.

When defining input transition it is allowed to use \texttt{INPUT\_CHAR} in any items
to be pushed into left/right stack. Here is an~example that takes a~character from input
tape and pushes it into the~left stack (and ignores symbols taken from both stacks).
\begin{verbatim}
state1 ALL ALL ->* state2 INPUT_CHAR NOTHING
\end{verbatim}

When defining output transition we \textbf{must} specify what character is printed
with adding \texttt{Output: <letter>} at the very back of transition definition.
An~example that prints letter taken from the~left stack (and ignores what was taken from right stack):
\begin{verbatim}
state1 ALL ALL ->^ state2 NOTHING NOTHING Output: ORIG_LEFT
\end{verbatim}
An~example that prints letter "a" (and ignores what was taken from stacks):
\begin{verbatim}
state1 ALL ALL ->^ state2 NOTHING NOTHING Output: "a"
\end{verbatim}

\textbf{Important note:} Order of defining transition matters. If patterns do not match
a~distinct set of letters then the transition that appeared first is applied.

\subsection{Example}

An~example (equivalent to the example from Turing Machine):
\begin{verbatim}
START: init_state
init_state $ $ -> s1 BLANK NOTHING
s1 ALL ALL ->* s2 INPUT_CHAR ORIG_RIGHT
s2 ALL ALL ->^ s3 ORIG_LEFT ORIG_RIGHT Output: ORIG_LEFT
s3 b $ -> s4 (ORIG_LEFT + BLANK) $
s3 b ALL -> s4 (ORIG_LEFT + ORIG_RIGHT) NOTHING
s3 B $ -> s4 (ORIG_LEFT + BLANK) $
s3 B ALL -> s4 (ORIG_LEFT + ORIG_RIGHT) NOTHING
s4 ALL ALL -> s5 "." ORIG_RIGHT
s5 ALL ALL ->^ s6 ORIG_LEFT ORIG_RIGHT Output: ORIG_LEFT
s6 ALL ALL -> END ORIG_LEFT ORIG_RIGHT
\end{verbatim}

\section {Counter Machine (4 counters)}

Counter Machine consists of $4$ counters each holding non-negative integer,
a~finite number of states and~transitions between them. Each transition
looks as follows:

\begin{verbatim}
state_name (pattern pattern pattern pattern) ->
    target_state (number number number number)
\end{verbatim}

Where:
\begin{itemize}
  \item \texttt{state\_name} is the state in which counter machine needs to be
      within for this transition to be applied,
  \item \texttt{pattern} is one of values \texttt{0}, \texttt{1} or \texttt{\_}
      meaning empty counter, non-empty counter and any counter state and defines
      what is expected state of the~given counter - the transition may be applied
      only when all counter states are matched (Notice that symbol \texttt{\_}
      is matched with any state of the counter),
  \item \texttt{target state} is the state in which machine will be after
      applying the transition,
  \item \texttt{number} is an~integer from the~range \texttt{[-1, MAX\_INT]} specifying
      what should be added to given counter - it is allowed to decrease counter
      by $1$ only, but it is possible to increase it by any number that can be stored
      in regular integer type.
\end{itemize}

\textbf{Note:} If there are many transitions that may be applied in given state
matching all counters \textbf{the first one} is applied. It means that order
of defining transitions matters.

It is required to give an~initial state of the machine with the following statement:
\begin{verbatim}
START: state_name
\end{verbatim}

\subsection {Extensions of the theoretical model}

Input/Output operations fit in the schema of using counters - input and output
are additional counters which transitions may use in a~similar way as counters are used.

Input transition is defined as follows:
\begin{verbatim}
state_name (counters) input pattern ->*
    target_state (numbers) input_operation
\end{verbatim}

Where:
\begin{itemize}
  \item \texttt{input\_pattern} is one of \texttt{0}, \texttt{1} or \texttt{\_}
      (same as counter pattern) and specifies what should be the state
      of input counter for this transition to be applied,
  \item \texttt{input\_operation} specifies what action should be performed
      on input counter and is one of \texttt{LOAD}, \texttt{-1} or \texttt{NOOP}
      meaning respectively loading a~character from stdin into the input counter,
      decrease input counter by \texttt{1} and leaving input counter untouched.
\end{itemize}

This transition reads from stdin into input counter:
\begin{verbatim}
state1 (_ _ _ _) _ ->* state2 (0 0 0 0) LOAD
\end{verbatim}

These transitions read the~value from input counter and store it in first counter:
\begin{verbatim}
state1 (_ _ _ _) 1 ->* state1 (1 0 0 0) -1
state1 (_ _ _ _) 0 ->* state2 (0 0 0 0) NOOP
\end{verbatim}

Note: It is assumed that transition may just decrease the input counter
and is not allowed to increase its value directly.

Output transition is defined as follows:
\begin{verbatim}
state_name (counters) ->^ target_state (numbers) Output: output_operation
\end{verbatim}

Where:
\begin{itemize}
  \item \texttt{output\_operation} specifies what should be performed
      on output counter and may be one of \texttt{FLUSH} or non-negative number,
      meaning respectively pushing counter to stdout and modifying
      the~value stored in the counter by the~given number.
\end{itemize}

These transitions print character stored in first counter:
\begin{verbatim}
state1 (1 _ _ _) ->^ state1 (-1 0 0 0) Output: 1
state1 (0 _ _ _) ->^ state2 (0 0 0 0) Output: FLUSH
\end{verbatim}

Note: It is assumed that transition may just increase the output counter
and is not allowed to decrease its value directly.


\subsection{Example}

Code that reads a~character from stdin doubles its ASCII value and prints the result.
\begin{verbatim}
START: s1
s1 (_ _ _ _) _ ->* s2 (0 0 0 0) LOAD
s2 (_ _ _ _) 1 ->* s2 (1 0 0 0) -1
s2 (_ _ _ _) 0 ->* s3 (0 0 0 0) NOOP
s3 (1 _ _ _) -> s3 (-1 2 0 0)
s3 (0 _ _ _) -> s4 (0 0 0 0)
s4 (_ 1 _ _) ->^ s4 (0 -1 0 0) Output: 1
s4 (_ 0 _ _) ->^ END (0 0 0 0) Output: FLUSH
\end{verbatim}

\section {Counter Machine (2 counters)}

Counter Machine with 2 counters has the same definition as
Counter Machine with 4 counters, but it is allowed to use only
2 counters, so transitions become of the form:

\begin{verbatim}
state_name (pattern pattern) -> target_state (number number)
\end{verbatim}

Input/Output is handled the same way it is handled in Counter Machine with 4 counters.


\chapter{Theoretical underpinnings}

\section {Reduction from Brainfuck to Turing Machine}

Brainfuck is really similar to Turing Machine, so it is relatively easy to build
a~translation. They both have a~tape and both can read and update symbols in any
cell of the~tape. There are two main differences: representation of states and
input/output handling.

\textit{States representation.}
Brainfuck has a~sequence of instructions that need to~be
executed one by~one in the~given order, while Turing Machine has unordered set
of states and transition function (defining how to move between them). Solution
is to give a~unique name to each instruction and specify transitions between
consecutive instructions. The only exception is a~loop, where depending on
symbol stored in current cell we perform transition to $1$ out of $2$ different states.
This is exactly what Turing Machine model provides -- depending on the~symbol
within current cell we apply appropriate transition.

\textit{Input/Output handling.}
Turing Machine can either accept or~reject given input, so it is necessary to
extend this theoretical model to allow side-effects like reading standard
input and writing to standard output. Even though there is a~way to give
input word (it should be initially written on the tape), this thesis assumes
there is separate source and separate destination for I/O operations.
It means that at any point we may load a~symbol into current cell or~send
any symbol (not necessary the one from current cell) to the~screen. This
way Brainfuck itself handles I/O as well which makes translation straightforward.

\section {Reduction from Turing Machine to 2 stack PDA}

Turing Machine operates on a~tape, while 2 stack PDA operates on 2 stacks, so we need
to come up with some idea how to represent a~tape using 2 stacks. This idea is well-known:
we cut the~tape into two pieces in a~way that current cell is at the~top of the~left stack and all
the cells from the~left side are lower in the~left stack and similarly all cells from the~right side
are stored in the~right stack (cell to the right of the~current cell is the top of the~right stack).

The only problem is the~fact that Turing Machine tape is infinite in one direction.
There is an~exact cell that contains the very last non-blank symbol, so we assume the~tape
ends at this symbol to perform our cut. If Turing machine at any point decides to extend
the tape it needs to first move into new cell (make this cell top of the~left stack in our PDA),
so at this point 2 stack PDA model can simply insert additional new element to the left
stack performing this extension.

It is clear what are the equivalent operations to the ones a~Turing Machine performs.
For example equivalent operation to updating current cell is taking one symbol from
the~top of left stack and push new symbol in its place. Moving one cell to the~right
is equivalent to taking one symbol from the~top of the~right stack and pushing it
into the~left stack -- if the~right stack is empty then we just push new blank symbol
to the~left stack.

\section {Reduction from 2 stack PDA to 4 Counter Machine}

Similarly to the~reduction from Turing Machine to 2 stack PDA we need to simulate
one memory model with the~other one. In this case we need to simulate $2$ stacks
with $4$ counters. More precisely, it is enough to show how to simulate $1$ stack
with $2$ counters and then apply the~same idea to both stacks.

Stack alphabet $\Gamma$ is finite and is of size $N = |\Gamma|$. Each symbol from $\Gamma$ may
be assigned a~unique number starting from $1$ up to $N$ ($0$ is problematic -- it will be
explained later). A~stack is a~sequence of numbers $a = a_0 a_1 a_2 \dots a_{k-1}$ (where $a_0$
is the~top of the~stack). Such a~sequence we may represent as a~single number in a~numeral system
with base $\bar{N} = N+1$:

$$ a_0 \cdot \bar{N}^0 + a_1 \cdot \bar{N}^1 + \dots + a_{k-1} \cdot \bar{N}^{k-1}
    = \sum_{i=0}^{k-1} a_i \cdot \bar{N}^i $$

Our left counter will hold whole stack as a~single number and our right counter will be used
to perform operations on the~left one. Because of this representation if we had some symbol $a$
with value $0$ then we would not distinguish between an~empty stack and the~one containing
a single $a$ (more precisely $0$ could represent a~stack containing any number of $a$'s
stored on this stack).

We will need a~few stack operations (and their equivalent
mathods on counters):
\begin{itemize}
  \item \textbf{pop} one symbol from the~top,
  \item \textbf{push} one symbol to the~top,
  \item \textbf{check} what is the~symbol at the~top.
\end{itemize}

To \textbf{pop} one symbol from the~stack we just perform an~integer division by $\bar{N}$ on
the~counter. To~perform this division we will decrease counter by $1$ at each step and every
$\bar{N}$-th step will increase the~helper counter by $1$. When the~original counter becomes empty
then in the~helper counter there is the~result of integer division by $\bar{N}$. Now we just
need to copy the~result from helper counter into the~original one. Whole operation is shown in
Figure \ref{fig:pop_operation}.

\begin{figure}[H]
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \begin{tikzpicture}[stack/.style={rectangle split, rectangle split parts=#1,draw, anchor=center}]
      \node[stack=5] at (0,0) {
        \nodepart{one}$a_0$
        \nodepart{two}$a_1$
        \nodepart{three}$a_2$
        \nodepart{four}$\dots$
        \nodepart{five}$a_{k-1}$
      };

      \node[stack=4] at (4,0) {
        \nodepart{one}$a_1$
        \nodepart{two}$a_2$
        \nodepart{three}$\dots$
        \nodepart{four}$a_{k-1}$
      };

      \draw [->, >=stealth] (1,0) -- (3,0) node [midway, above, sloped] (TextNode) {\textbf{pop}};
    \end{tikzpicture}

    \captionsetup{font=footnotesize}
    \caption{Pop element $a_0$ from the top.}

  \end{subfigure}
  \begin{subfigure}[b]{0.6\textwidth}
    \centering
    \begin{tikzpicture}[stack/.style={rectangle split, rectangle split parts=#1,draw, anchor=center}]

      \node[stack=1] at (0,0) {
        \nodepart{one}$S$
      };

      \node[stack=1] at (5,0) {
        \nodepart{one}$S'$
      };

      \def\myshift#1{\raisebox{.5ex}}
      \draw [->,>=stealth,postaction={decorate,
          decoration={text along path,text align=center,
          text={|\myshift|divide by {$\bar{N}$}}}}]
      (0.5,0.1) to[bend left=45] (4.5,0.1);

      \draw [<-,>=stealth,postaction={decorate,
          decoration={text along path,text align=center,
          text={|\myshift|copy}}}]
      (0.5,-0.1) to[bend right=45] (4.5,-0.1);

    \end{tikzpicture}

    \captionsetup{font=footnotesize}
    \caption{Pop element from the~stack described as number $S$.}

  \end{subfigure}

  \caption{Stack vs. counter --- \textbf{pop} operation.}
  \label{fig:pop_operation}

\end{figure}

To \textbf{push} symbol $b$ to the~top of the stack we need to multiply the~counter
by $\bar{N}$ and add number $\bar{b}$ corresponding to symbol $b$:
$$ \bar{b} + \bar{N} \cdot
    \Big[ a_0 \cdot \bar{N}^0 + a_1 \cdot \bar{N}^1 + \dots
    + a_{k-1} \cdot \bar{N}^{k-1} \Big]
    = \bar{b} + \sum_{i=0}^{k-1} a_i \cdot \bar{N}^{i+1} $$
Schematic operations to push stack symbol into a~stack represented as a~number is
shown in Fugure \ref{fig:push_operation}.

\begin{figure}[H]
  \begin{subfigure}[b]{0.4\textwidth}
    \centering
    \begin{tikzpicture}[stack/.style={rectangle split, rectangle split parts=#1,draw, anchor=center}]
      \node[stack=4] at (0,0) {
        \nodepart{one}$a_0$
        \nodepart{two}$a_1$
        \nodepart{three}$\dots$
        \nodepart{four}$a_{k-1}$
      };

      \node[stack=5] at (4,0) {
        \nodepart{one}$b$
        \nodepart{two}$a_0$
        \nodepart{three}$a_1$
        \nodepart{four}$\dots$
        \nodepart{five}$a_{k-1}$
      };

      \draw [->, >=stealth] (1,0) -- (3,0) node [midway, above, sloped] (TextNode) {\textbf{push} $b$};
    \end{tikzpicture}

    \captionsetup{font=footnotesize}
    \caption{Push element $b$ to the top.}

  \end{subfigure}
  \begin{subfigure}[b]{0.6\textwidth}
    \centering
    \begin{tikzpicture}[stack/.style={rectangle split, rectangle split parts=#1,draw, anchor=center}]

      \node[stack=1] at (0,0) {
        \nodepart{one}$S$
      };

      \node[stack=1] at (5,0) {
        \nodepart{one}$S'$
      };

      \def\myshift#1{\raisebox{.5ex}}
      \draw [->,>=stealth,postaction={decorate,
          decoration={text along path,text align=center,
          text={|\myshift|multiply by {$\bar{N}$}}}}]
      (0.5,0.1) to[bend left=45] (4.5,0.1);

      \draw [<-,>=stealth,postaction={decorate,
          decoration={text along path,text align=center,
          text={|\myshift|copy}}}]
      (0.5,-0.1) to[bend right=45] (4.5,-0.1);

      \def\myshift#1{\raisebox{.5ex}}
      \draw [->,shorten <=5pt,shorten >=5pt,>=stealth,postaction={decorate,
          decoration={text along path,text align=center,
          text={|\myshift|add {$b$}}}}]
      (5.5,0.1) arc (180:-180:0.7);

    \end{tikzpicture}

    \captionsetup{font=footnotesize}
    \caption{Push element $b$ to the~stack described as number $S$.}

  \end{subfigure}

  \caption{Stack vs. counter --- \textbf{push} operation.}
  \label{fig:push_operation}

\end{figure}


The hardest part is to recognize what is the~top symbol -- \textbf{check} operation.
The idea is simple -- we need to calculate the~remainder from division by $\bar{N}$:
$$ \Bigg( \sum_{i=0}^{k-1} a_i \cdot \bar{N}^i \Bigg) \ \mathrm{mod} \ \bar{N} = a_0 $$
The only place we can remember any information are states. This means that we need
to end up within different state for each remainder -- we call a~state $R_i$ if
recognized symbol has number $i$. Consider example alphabet having $9$ symbols -- Figure
\ref{fig:check} shows all states and transitions needed to~recognize it. Each
transition labelled with $0$ is applied only when counter is empty, similarly
all those labelled with $1$ apply when it is not empty. Additionally when we move around
the~circle (apply transition labelled with $1$) we always decrease the~counter.

\begin{figure}[H]
\centering
\begin{tikzpicture}
\foreach \a in {0,1,...,9}{
  \ifnum\a=0 {
    \node [state,initial] (q0) at (180: 2.5cm) {$q_0$};
  }
  \else{
    \node [state] (q\a) at (-\a*360/10 + 180: 2.5cm) {$q_{\a}$};
  }\fi
}

\foreach \a in {1,2,...,9}{
  \xdef \textplace {right}
  \ifnum\a>4 {\xdef \textplace {left}}\fi
  \ifnum\a=1 {\xdef \textplace {above}}\fi
  \ifnum\a=4 {\xdef \textplace {above}}\fi
  \ifnum\a=5 {\xdef \textplace {above}}\fi
  \ifnum\a=6 {\xdef \textplace {below}}\fi
  \ifnum\a=9 {\xdef \textplace {below}}\fi
  \node [state,accepting] (R\a) at (-\a*360/10 + 180: 5cm) {$R_{\a}$};
  \path[->] (q\a) edge node [\textplace] {0} (R\a);
}

\foreach \a in {0,1,...,9}{
  \xdef \textplace {above}
  \ifnum\a>4 {\xdef \textplace {below}}\fi
  \ifnum\a=0 {\xdef \textplace {left}}\fi
  \ifnum\a=9 {\xdef \textplace {left}}\fi
  \ifnum\a=4 {\xdef \textplace {right}}\fi
  \ifnum\a=5 {\xdef \textplace {right}}\fi
  \path[->] (q\a) edge [bend left=20] node [\textplace] {1} (q\intcalcMod{\a+1}{10});
}
\end{tikzpicture}

\caption{Recognizing symbol from alphabet of size $9$. $R_i$ is the~state with recognized
  symbol $i$, labels on paths define whether counter is empty (0) or not (1).}
\label{fig:check}

\end{figure}

When a~counter value decreases to $0$ then we move to some state $R_i$ (notice that for
correct representations of stacks we never get a~remainder equal $0$, so we never end within $q_0$).
If we do not want to destroy original counter value (which is stack representation) we need
to copy it into our counter for computations and after regognizing symbol at the~top
we need to copy it back to the original counter.

\textit{How to put it all together?}

Because all transitions (in any presented model) are independent, we may focus on a~single
transition and when we build a~translation for it then we can build a~translation for the~whole
program (as long as we keep the~order of transitions).

Each 2 stack PDA transition \texttt{T} has a~\texttt{state} the~model needs to be within,
an~\texttt{other\_state} to which the~model moves into \textbf{if both stack symbol match
the~patterns}.

\begin{verbatim}
state left_symbol right_symbol -> other_state [...]
\end{verbatim}

We will keep state names and build a~new 4 Counter Machine model that will operate as well
on states \texttt{state} and \texttt{other\_state}, but it will have some additional ones
in between. When we want to check whether $T$ should be applied then we perform two
\textbf{check} operations. Because both symbols need to match, after recognizing first symbol
we need to recognize the other without loosing the information about the~first one. This
means that we build a~structure from Figure \ref{fig:check} and in place of each $R_i$ we
paste the same structure for symbols recognition. All unsuccessful paths (symbols not matched)
return to \texttt{state} and successful ones end up within \texttt{other\_state}.

This idea gives O($m^2$) new transitions, where $m$ is the~number of transitions in 2 stack PDA
program. If we consider input counter (which is yet another input stack) then we get O($m^3$)
transitions that we generate. (Fortunately implementation optimizations make it O($m^2$).)

There are still a~few more details to handle:
\begin{itemize}
  \item each applied transition performs a~\textbf{pop} (it always pops a~top element),
  \item transitions may push some items to the stacks (these items may contain symbols that
      were just popped),
  \item a~transition may contain output instruction.
\end{itemize}

Notice that pushing symbols (even few ones) is easy -- we need to apply \textbf{push} operation
multiple times, no matter if it is a~stack or an~output. It is worth to notice
that building this structure takes O($N$) new states assuming the~number of symbols
to push is a~constant. The whole transition $T$ takes O($N \cdot m^2$) newly
generated states.

In practice we want to pop elements together with recognizing them, but now we define the~idea, so
is is enough to say that we perform a~\textbf{pop} after making sure we should apply transition $T$.

\section {Reduction from 4 Counter Machine to 2 Counter Machine}

\todo{Opis}


\todo{\sout{O tym, jak te redukcje działają}}

\chapter{Implementation}

\section{Ogólny wstęp}

\todo{Uzasadnienie doboru narzędzi}

\todo{Najciekawsze wyzwania}

\todo{Wszystko, co było ciekawe}

\section{Szczegóły techniczne}

\todo{Co jest gdzie, jak to się uruchamia, itd. / skrócona instrukcja użytkownika}

\todo{Ograniczenia implementacji}

\section{Przykłady}

Dużo przykładów...

\section{Ewaluacja}

Porównanie czasów

Tabelka


\section{Optymalizacje}

\chapter{Podsumowanie, wnioski, możliwości kontynuowania}

\bibliographystyle{plain}
\bibliography{thesis}{}

\appendix

\chapter{Szczegółowy sposób instalacji i konfiguracji lub dostępu do działającego systemu oraz podręcznik użytkownika systemu.}

%%%%% BIBLIOGRAFIA






\end{document}
